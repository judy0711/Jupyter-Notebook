{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.24.0\n"
     ]
    }
   ],
   "source": [
    "print(requests.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "request_url = \"https://ecshweb.pchome.com.tw/search/v3.3/all/results\"\n",
    "query_str-params = {\n",
    "    'q': 'otterbox',\n",
    "    'page': 2,\n",
    "    'sort': 'sale/dc'\n",
    "}\n",
    "\n",
    "response = requests.get(request_url, params=query_str_params)\n",
    "print(type(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "request_url = \"https://ecshweb.pchome.com.tw/search/v3.3/all/results\" \n",
    "query_str_params = {\n",
    "    'q': 'macbook',\n",
    "    'page': 1,\n",
    "    'sort': 'rnk/dc'\n",
    "}\n",
    "\n",
    "response = requests.get(request_url, params=query_str_params)\n",
    "#print(type(response)\n",
    "#print(type(response.text))\n",
    "print(type(response.json())) #works only response body is JSON format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests        # response.json()\n",
    "import json    # for JSON format\n",
    "import xml.etree.ElementTree as ET  # for XML format\n",
    "from bs4 import BeautifulSoup # for HTML format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['QTime', 'totalRows', 'totalPage', 'range', 'cateName', 'q', 'subq', 'token', 'isMust', 'prods'])\n",
      "29355\n"
     ]
    }
   ],
   "source": [
    "json_format = response.json() #response is in JSON format\n",
    "print(type(json_format))\n",
    "print(json_format.keys())\n",
    "print(json_format['prods'][0]['price'])   #the price of the first item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_url = \"https://emap.pcsc.com.tw/EMapSDK.aspx\"\n",
    "form_data = {\n",
    "    'commandid': 'SearchStore',\n",
    "    'city': '台北市',\n",
    "    'town': '大安區'\n",
    "}\n",
    "response = requests.post(request_url, data=form_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'xml.etree.ElementTree.Element'>\n"
     ]
    }
   ],
   "source": [
    "#import xml.etree.ElementTree as ET\n",
    "\n",
    "#print(type(response.text) #str:unstructured\n",
    "root = ET.fromstring(response.text)  #parsing: unstructured -> structured\n",
    "print(type(root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['大台', '大信', '大敦', '中廣', '仁安', '仕吉', '北科大', '台科一', '永康', '禾光', '立仁', '光忠', '吉孝', '吉忠', '合旺', '合維', '安居', '安松', '佑安', '技安', '辛亥', '卓聯', '和平東', '和安', '和金', '和泰', '和樂', '延吉', '昇隆', '東門', '欣安和', '欣隆昌', '花市', '金信', '金華', '長星', '阿波羅', '信中', '信安', '信義', '信興', '建安', '建忠', '建南', '建綸', '恆安', '科技站', '科建', '科興', '師大', '泰利', '國館', '崇光', '康福', '教育大學', '統合', '統家', '統領', '通化', '頂好', '頂安', '頂東', '喜悅', '富陽', '復忠', '復昌', '復維', '敦仁', '敦禾', '敦安', '敦信', '敦南', '敦頂', '敦隆', '敦維', '敦親', '森美', '華電', '愛國', '新北科', '新東帝', '新泰順', '新國聯', '溫州', '溫東', '瑞升', '瑞安', '義村', '誠安', '福亭', '鳳翔', '樂安', '樂利', '樂和', '樂隆', '黎元', '豫銘', '錢忠', '靜安', '龍和', '龍延', '龍門', '龍泉', '龍淵', '龍普', '濟南', '臨江', '臨通', '豐安', '懷生', '羅鑫', '麟光', '鑫忠孝', '鑫泰', '鑫通', '鑫富民', '鑫復']\n"
     ]
    }
   ],
   "source": [
    "# The XPath for POIName\n",
    "poiname_xpath = './/POIName' #xpath\n",
    "poinames = [e.text for e in root.findall(poiname_xpath)]\n",
    "print(poinames)\n",
    "\n",
    "\n",
    "#root.findall(poiname_xpath)[0].text\n",
    "#root.findall(poiname_xpath)[1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['台北市大安區羅斯福路三段283巷14弄16號1樓', '台北市大安區信義路三段33號', '台北市大安區敦化南路二段63巷7號1樓', '台北市大安區仁愛路三段25-1號27號', '台北市大安區仁愛路四段27巷1號', '台北市大安區忠孝東路四段223巷42號', '台北市大安區忠孝東路三段1號(台北科技大學大川堂)', '台北市大安區基隆路四段43號1樓', '台北市大安區永康街43號', '台北市大安區和平東路二段63號1樓', '台北市大安區安和路二段74巷1號', '台北市大安區復興南路一段107巷5弄1號1樓', '台北市大安區忠孝東路四段299號', '台北市大安區延吉街72號', '台北市大安區復興南路二段151巷41號', '台北市大安區四維路170巷8號1樓', '台北市大安區安居街33號', '台北市大安區安東街50之2號50之3號50之4號', '台北市大安區忠孝東路三段217巷1弄2號', '台北市大安區和平東路三段97號', '台北市大安區辛亥路二段57號', '台北市大安區羅斯福路四段1號1樓卓聯大樓', '台北市大安區和平東路一段129之1號', '台北市大安區和平東路三段230號', '台北市大安區和平東路一段91號', '台北市大安區和平東路一段169號', '台北市大安區和平東路三段228巷45號1樓', '台北市大安區延吉街237號', '台北市大安區敦化南路二段238號', '台北市大安區信義路二段198巷6號1樓', '台北市大安區安和路一段47號', '台北市大安區基隆路二段142之1號及142之2號', '台北市大安區建國南路一段274號', '台北市大安區金山南路二段18號1樓', '台北市大安區金華街140號1樓', '台北市大安區基隆路三段85號', '台北市大安區忠孝東路四段222號224號1樓', '台北市大安區信義路三段101號', '台北市大安區大安路一段218號', '台北市大安區信義路四段265巷12弄1號', '台北市大安區信義路四段32號', '台北市大安區敦化南路一段187巷29號', '台北市大安區忠孝東路三段249號', '台北市大安區建國南路二段151巷6之8號', '台北市大安區仁愛路四段151巷33號忠孝東路四段216巷32弄19號21號', '台北市大安區永康街2巷12號1樓', '台北市大安區復興南路二段203號', '台北市大安區建國南路一段28號30號', '台北市大安區復興南路二段271巷2號1樓', '台北市大安區師大路87號', '台北市大安區仁愛路四段266巷15弄22號', '台北市大安區光復南路240巷25號', '台北市大安區復興南路一段135巷5號', '台北市大安區永康街12之2號1樓', '台北市大安區敦南街38號', '台北市大安區忠孝東路四段181巷7弄11之1號11之2號', '台北市大安區忠孝東路四段216巷27弄1號1樓', '台北市大安區忠孝東路四段205巷7弄5號1樓', '台北市大安區通化街26之8號', '台北市大安區仁愛路四段79號1號', '台北市大安區大安路一段67號1樓', '台北市大安區大安路一段43號', '台北市大安區復興南路二段82-1及82-2號', '台北市大安區和平東路三段298號300號1樓', '台北市大安區光復南路98之3號98之5號', '台北市大安區通化里光復南路616號', '台北市大安區復興南路二段17號', '台北市大安區忠孝東路四段148號部份', '台北市大安區敦化南路二段265巷6號1樓', '台北市大安區安和路一段86號', '台北市大安區仁愛路四段122巷50號1樓', '台北市大安區敦化南路一段236巷13號', '台北市大安區忠孝東路四段101巷7號', '台北市大安區敦化南路二段182號', '台北市大安區東豐街43號45號1樓', '台北市大安區辛亥路二段171巷8號', '台北市大安區信義路三段65號1樓', '台北市大安區通化街177號', '台北市大安區愛國東路75號', '台北市大安區新生南路一段3號B1樓', '台北市大安區敦化南路二段99號1樓', '台北市大安區泰順街13號', '台北市大安區光復南路180巷12號', '台北市大安區羅斯福路三段245號', '台北市大安區和平東路一段266號', '台北市大安區杭州南路二段91號', '台北市大安區瑞安街182號', '台北市大安區忠孝東路三段160號', '台北市大安區敦化南路一段247巷12號1樓', '台北市大安區羅斯福路二段31號1樓', '台北市大安區忠孝東路四段216巷68號', '台北市大安區樂業街71號73號', '台北市大安區樂利路76號78號1樓', '台北市大安區樂利路29號29-1號', '台北市大安區敦化南路二段331巷14號', '台北市大安區臥龍街188巷1號', '台北市大安區大安路二段102號', '台北市大安區忠孝東路四段26巷5號', '台北市大安區光復南路262號', '台北市大安區和平東路二段197號199號1樓', '台北市大安區師大路59巷13號', '台北市大安區和平東路二段38之1號40號1樓', '台北市大安區羅斯福路三段193號1樓', '台北市大安區和平東路二段118巷33號', '台北市大安區敦化南路一段233巷25號', '台北市大安區濟南路三段12號1樓', '台北市大安區安和路二段67號', '台北市大安區通安街64號1樓', '台北市大安區東豐街9號', '台北市大安區忠孝東路三段248巷9號', '台北市大安區羅斯福路三段29號31號1樓', '台北市大安區臥龍街252號及252-1號', '台北市大安區忠孝東路四段313號1樓', '台北市大安區古風里泰順街64號1樓', '台北市大安區信義路四段294巷7號1樓', '台北市大安區忠孝東路四段181巷40弄22號1樓', '台北市大安區信義路三段178號1樓']\n"
     ]
    }
   ],
   "source": [
    "# The XPath for Address\n",
    "addresses = [e.text for e in root.findall('.//Address')]\n",
    "print(addresses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_url = \"https://www.imdb.com/title/tt10048342\"\n",
    "response = requests.get(request_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "399254\n",
      "<class 'bs4.BeautifulSoup'>\n"
     ]
    }
   ],
   "source": [
    "#from bs4 import BeautifulSoup\n",
    "\n",
    "print(type(response.text)) #str: unstructured\n",
    "print(len(response.text))\n",
    "soup = BeautifulSoup(response.text)  #parsing\n",
    "print(type(soup)) #Beautiful Soup: Structured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "后翼棄兵\n"
     ]
    }
   ],
   "source": [
    "# The CSS Selector for title\n",
    "title = soup.select('h1')[0].text.strip()\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span itemprop=\"ratingValue\">8.6</span>,\n",
       " <span class=\"grey\">/</span>,\n",
       " <span class=\"grey\" itemprop=\"bestRating\">10</span>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select('.ratingValue span')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.6\n"
     ]
    }
   ],
   "source": [
    "rating = float(soup.select('strong span')[0].text)\n",
    "print(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://m.media-amazon.com/images/M/MV5BM2EwMmRhMmUtMzBmMS00ZDQ3LTg4OGEtNjlkODk3ZTMxMmJlXkEyXkFqcGdeQXVyMjM5ODk1NDU@._V1_UX182_CR0,0,182,268_AL_.jpg\n"
     ]
    }
   ],
   "source": [
    "# The CSS Selector for poster\n",
    "poster = soup.select('.poster img')[0].get('src')\n",
    "print(poster)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Drama']\n",
      "TV Mini-Series (2020)\n"
     ]
    }
   ],
   "source": [
    "genre = [e.text for e in soup.select('.subtext a')]\n",
    "release_date = genre.pop()\n",
    "release_date = release_date.strip()\n",
    "print(genre)\n",
    "print(release_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Anya Taylor-Joy', 'Chloe Pirrie', 'Bill Camp', 'Marcin Dorocinski', 'Marielle Heller', 'Thomas Brodie-Sangster', 'Moses Ingram', 'Harry Melling', 'Isla Johnston', 'Janina Elkin', 'Matthew Dennis Lewis', 'Russell Dennis Lewis', 'Patrick Kennedy', 'Christiane Seidel', 'Jacob Fortune-Lloyd', 'Akemnji Ndifornyen', 'Annabeth Kelly', 'Dolores Carbonari', 'Zoé Höche', 'Andruscha Hilscher', 'Iskander Madjitov', 'Rebecca Root', 'Clement Guyot', 'Frederic Stromenger', 'Sophie McShera', 'Katherine Towe', 'Mia-Luisa Schrader', 'Laura Danne', 'Nina Herzberg', 'Richard Waugh', 'Marian Meder', 'Frieda Raab', 'Sergio Di Zio', 'Emma Henker', 'William Horberg', 'Lucy Ella von Scheele', 'Alva Schäfer', 'Marlene Leinemann', 'Matteo Vinogradov', 'Max Krause', 'Ryan Wichert', 'Eloise Webb', 'Millie Brady', 'Rebecca Dyson-Smith', 'Felice', 'Frederik Schmid', 'Philipp Droste', 'Nikolai Jegorow', 'Daniel Brunet', 'Maximilian Frisch', 'Sam Gilroy', 'Sophia Frank', 'Raphael Keric', 'Adrian Hagenguth', 'Salber Lee Williams', 'Alexander Albrecht', 'Ilja Roßbander', 'Simon Jensen', 'Jeremy Mockridge', 'Frederik Funke', 'Alec Dahmer', 'Simon Jansen', 'Samantha Soule', 'Uke Bosse', 'Ben Gageik', 'Pia Schlipphak', 'Drew Doyle', 'Dmitriy Frid', 'David Gorelik', 'Pablo Scola', 'Peter Gilbert Cotton', 'Paul Johnston', 'Frédéric Vonhof', 'Jenny Galloway', 'Lily Lesser', 'Charlotte Lucas', 'Rahul Chakraborty', 'Nicky Goldie', 'Maximilian Diehle', 'Maria Heinsch', 'John Schwab', 'Paul Walther', 'Lukas Huber', 'Juri Padel', 'Evgenij Verenin', 'Konstantin Frank', 'Jennifer Haas', 'Marja Haensch', 'Marcus Loges', 'Rosalie Craig', 'Tim Kalkhof', 'Ben Moor', 'Alberto Ruano', 'Colin Stinton', 'Michel Diercks', 'Jan Nahuel Häfliger', 'Elvis Nowatzki', 'Ben Posener', 'Matthew Rowsell', 'Dora Zygouri', 'Hugo Grimm', 'William von Tagen', 'Adrian Zwicker', 'Louis Ashbourne Serkis', 'Vlad Chiriac', 'Anna Hauss', \"Jonjo O'Neill\", 'Till Trenkel', 'Josepha Walter', 'Ricky Watson', 'Marc Bergemann']\n"
     ]
    }
   ],
   "source": [
    "cast = [elem_tag.text.strip() for elem_tag in soup.select('.primary_photo+ td a')]\n",
    "print (cast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['7 episodes, 2020', '6 episodes, 2020', '5 episodes, 2020', '5 episodes, 2020', '5 episodes, 2020', '4 episodes, 2020', '4 episodes, 2020', '4 episodes, 2020', '4 episodes, 2020', '4 episodes, 2020', '4 episodes, 2020', '4 episodes, 2020', '3 episodes, 2020', '3 episodes, 2020', '4 episodes, 2020', '3 episodes, 2020', '3 episodes, 2020', '4 episodes, 2020', '3 episodes, 2020', '3 episodes, 2020', '3 episodes, 2020', '2 episodes, 2020', '2 episodes, 2020', '2 episodes, 2020', '2 episodes, 2020', '2 episodes, 2020', '2 episodes, 2020', '2 episodes, 2020', '2 episodes, 2020', '2 episodes, 2020', '2 episodes, 2020', '2 episodes, 2020', '3 episodes, 2020', '2 episodes, 2020', '2 episodes, 2020', '2 episodes, 2020', '2 episodes, 2020', '2 episodes, 2020', '2 episodes, 2020', '2 episodes, 2020', '2 episodes, 2020', '2 episodes, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '2 episodes, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '1 episode, 2020', '2 episodes, 2020', '1 episode, 2020', '2 episodes, 2020']\n"
     ]
    }
   ],
   "source": [
    "cast_characters = [elem_tag.text.strip() for elem_tag in soup.select('.cast_list a') if len(elem_tag.text) > 0]\n",
    "cast = cast_characters[::3]\n",
    "characters = cast_characters[1::3]\n",
    "episode = cast_characters[2::3]\n",
    "print(episode)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
